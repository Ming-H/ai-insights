name: Sync Content from ContentForge AI

on:
  schedule:
    # 每天多次同步，对应 content-forge-ai 的更新时间
    # 为了避免生成未完成，延后 45 分钟同步
    # 06:00 生成 => 06:45 同步（北京时间），即 UTC 22:45
    - cron: '45 22 * * *'
    # 12:00 生成 => 12:45 同步（北京时间），即 UTC 04:45
    - cron: '45 4 * * *'
    # 18:00 生成 => 18:45 同步（北京时间），即 UTC 10:45
    - cron: '45 10 * * *'
  workflow_dispatch:
  # 允许从 content-forge-ai 仓库触发同步
  repository_dispatch:
    types: [content-updated]

permissions:
  contents: write

concurrency:
  group: sync-content-${{ github.ref }}
  cancel-in-progress: false

jobs:
  sync:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout ai-insights
        uses: actions/checkout@v4
        with:
          path: ai-insights

      # 检出 content-forge-ai 仓库（公开仓库，无需 token）
      - name: Checkout content-forge-ai
        uses: actions/checkout@v4
        with:
          repository: Ming-H/content-forge-ai
          path: content-forge-ai
          fetch-depth: 0  # Get full history to ensure we get the latest commit

      # 确保获取最新的提交（解决跨仓库同步延迟问题）
      - name: Fetch latest content-forge-ai commits
        run: |
          cd content-forge-ai
          git fetch origin main
          git checkout origin/main
          echo "Latest commit in content-forge-ai:"
          git log -1 --format="%H %s %ci"

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Verify content sources
        run: |
          echo "========================================"
          echo "Sync workflow starting"
          echo "========================================"
          echo "Trigger: ${{ github.event_name }}"
          echo "ContentForge AI path: $GITHUB_WORKSPACE/content-forge-ai"
          echo "AI Insights path: $GITHUB_WORKSPACE/ai-insights"
          echo "Time: $(TZ=Asia/Shanghai date '+%Y-%m-%d %H:%M:%S') (Beijing)"
          echo "========================================"

          ls -la $GITHUB_WORKSPACE/content-forge-ai/data/daily/ | head -20 || echo "content-forge-ai/data/daily not found"

      # For all triggers, check if today's digest exists.
      # repository_dispatch may race with source push visibility, so we retry with re-fetch.
      - name: "Check for today's digest"
        id: check-digest
        env:
          TZ: Asia/Shanghai
        run: |
          set -euo pipefail
          echo "========================================"
          echo "Checking for today's digest"
          echo "========================================"

          today=$(TZ=$TZ date +%Y%m%d)
          digest_dir="$GITHUB_WORKSPACE/content-forge-ai/data/daily/$today/digest"

          echo "Expected digest directory: $digest_dir"
          echo "Today's date (Beijing): $today"

          has_today_digest=false

          # Check if today's digest exists
          if [ -d "$digest_dir" ]; then
            has_today_digest=true
          elif [ "${{ github.event_name }}" != "schedule" ]; then
            # repository_dispatch may arrive slightly before source checkout sees newest commit.
            # Re-fetch source repo and retry to avoid missing the newly generated digest.
            for attempt in 1 2 3 4 5 6 7 8 9 10; do
              echo "Digest not found, retry $attempt/10 after refreshing source repo..."
              sleep 30
              cd "$GITHUB_WORKSPACE/content-forge-ai"
              git fetch origin main
              git checkout origin/main

              if [ -d "$digest_dir" ]; then
                has_today_digest=true
                break
              fi
            done
          fi

          if [ "$has_today_digest" = "true" ]; then
            echo "Found today's digest directory ($today)"
            ls -la "$digest_dir"
            echo "has_today_digest=true" >> $GITHUB_OUTPUT
          else
            echo "Today's digest not found after checks ($today)"
            echo "has_today_digest=false" >> $GITHUB_OUTPUT
          fi

          # Always sync all available content to avoid missing late data from previous runs.
          echo "should_sync=true" >> $GITHUB_OUTPUT

      - name: Sync content (when digest found or non-scheduled)
        if: steps.check-digest.outputs.should_sync == 'true'
        run: |
          cd ai-insights
          echo "========================================"
          echo "Starting content sync..."
          echo "========================================"
          export CONTENT_FORGE_AI_PATH="$GITHUB_WORKSPACE/content-forge-ai"
          export HUGO_CONTENT_PATH="$GITHUB_WORKSPACE/ai-insights/content"

          python scripts/sync_content.py --all

          echo "========================================"
          echo "Content sync complete"
          echo "========================================"

          echo "Latest daily files:"
          ls -lt content/daily/*.md 2>/dev/null | head -5 || echo "No new daily files"

      - name: Verify latest digest is synced
        if: steps.check-digest.outputs.should_sync == 'true'
        run: |
          set -euo pipefail

          source_latest_digest=$(find "$GITHUB_WORKSPACE/content-forge-ai/data/daily" -type f -path "*/digest/digest_*.md" | sort | tail -1 || true)
          if [ -z "$source_latest_digest" ]; then
            echo "No digest files found in content-forge-ai; skip strict verification"
            exit 0
          fi

          digest_name=$(basename "$source_latest_digest")
          expected_date=$(echo "$digest_name" | sed -n 's/^digest_\([0-9]\{8\}\).*/\1/p')
          if [ -z "$expected_date" ]; then
            echo "Failed to parse date from digest filename: $digest_name"
            exit 1
          fi

          expected_file="${expected_date:0:4}-${expected_date:4:2}-${expected_date:6:2}-index.md"
          target_file="$GITHUB_WORKSPACE/ai-insights/content/daily/$expected_file"

          echo "Latest source digest: $source_latest_digest"
          echo "Expected target file: $target_file"

          if [ ! -f "$target_file" ]; then
            echo "ERROR: Latest source digest has not been synced to ai-insights"
            exit 1
          fi

      - name: Check for changes
        id: check-changes
        if: steps.check-digest.outputs.should_sync == 'true'
        run: |
          cd ai-insights
          # Stage generated content before checking changes so new files are detected.
          git add -A content/

          if git diff --cached --quiet; then
            echo "has_changes=false" >> $GITHUB_OUTPUT
            echo "No new content changes detected"
          else
            echo "has_changes=true" >> $GITHUB_OUTPUT
            echo "New content changes detected"
            git diff --cached --name-status
          fi

      - name: Commit and push
        if: steps.check-digest.outputs.should_sync == 'true' && steps.check-changes.outputs.has_changes == 'true'
        run: |
          set -euo pipefail
          cd ai-insights
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"

          echo "========================================"
          echo "Committing changes to repository..."
          echo "========================================"

          # Stage generated content to ensure latest workspace state is committed.
          git add -A content/

          # Re-check staged content before commit.
          if git diff --cached --quiet; then
            echo "No content changes to commit"
            exit 0
          fi

          echo "Files to commit:"
          git diff --cached --name-status

          # Commit synced content
          git commit -m "chore: sync content from content-forge-ai" \
                     -m "Trigger: ${{ github.event_name }}" \
                     -m "Sync time: $(date '+%Y-%m-%d %H:%M:%S') (UTC)"

          # Rebase local sync commit onto latest remote main, then push with retry.
          pushed=false
          for attempt in 1 2 3; do
            echo "Push attempt $attempt/3"
            if git pull --rebase origin main && git push; then
              pushed=true
              break
            fi

            echo "Push attempt $attempt failed, retrying in 10 seconds..."
            sleep 10
          done

          if [ "$pushed" != "true" ]; then
            echo "ERROR: Failed to push synced content after retries"
            exit 1
          fi

          echo "========================================"
          echo "Content successfully synced and pushed to repository"
          echo "========================================"

      - name: Summary report
        if: always()
        run: |
          echo "========================================"
          echo "Content Sync Report"
          echo "========================================"
          echo "Trigger: ${{ github.event_name }}"
          echo "Time: $(TZ=Asia/Shanghai date '+%Y-%m-%d %H:%M:%S') (Beijing)"
          echo "Status: ${{ job.status }}"
          echo "Should sync: ${{ steps.check-digest.outputs.should_sync }}"
          echo "Has changes: ${{ steps.check-changes.outputs.has_changes }}"
          echo "========================================"

      - name: Notify Feishu on sync failure
        if: failure() && secrets.FEISHU_WEBHOOK_URL != ''
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: |
          set -euo pipefail

          run_url="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          ts=$(TZ=Asia/Shanghai date '+%Y-%m-%d %H:%M:%S')
          msg=$(printf '%s\n' \
            '[AI-Insights][告警] 内容同步失败' \
            '仓库: ${{ github.repository }}' \
            '工作流: ${{ github.workflow }}' \
            '触发方式: ${{ github.event_name }}' \
            '分支: ${{ github.ref_name }}' \
            '提交: ${{ github.sha }}' \
            "时间(北京): $ts" \
            "详情: $run_url")

          export MSG="$msg"
          payload=$(python -c 'import json, os; print(json.dumps({"msg_type":"text","content":{"text":os.environ["MSG"]}}, ensure_ascii=False))')
          curl -sS -X POST "$FEISHU_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "$payload" >/dev/null
