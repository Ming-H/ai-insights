#!/usr/bin/env python3
"""
å†…å®¹åŒæ­¥è„šæœ¬ - ä» content-forge-ai åŒæ­¥å†…å®¹åˆ° Hugo åšå®¢

ç”¨æ³•:
    python scripts/sync_content.py --daily    # åŒæ­¥æ¯æ—¥ç®€æŠ¥
    python scripts/sync_content.py --series   # åŒæ­¥ç³»åˆ—æ–‡ç« 
    python scripts/sync_content.py --all      # åŒæ­¥å…¨éƒ¨å†…å®¹
"""

# é…ç½®è·¯å¾„ï¼ˆæ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–ï¼Œæ–¹ä¾¿ GitHub Actions / ä¸åŒç¯å¢ƒï¼‰
# æ³¨æ„ï¼šå¿…é¡»åœ¨æœ€å‰é¢å¯¼å…¥å¹¶è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œç¡®ä¿åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—å‰ç”Ÿæ•ˆ
import os
from pathlib import Path

# ä»ç¯å¢ƒå˜é‡è·å–è·¯å¾„
CONTENT_FORGE_AI_PATH = Path(os.getenv("CONTENT_FORGE_AI_PATH", "/Users/z/Documents/work/content-forge-ai"))
HUGO_CONTENT_PATH = Path(os.getenv("HUGO_CONTENT_PATH", "/Users/z/Documents/work/ai-insights/content"))

import sys
import json
import shutil
import argparse
import re
from datetime import datetime


def parse_date_from_digest_filename(filename):
    """ä» digest æ–‡ä»¶åè§£ææ—¥æœŸ"""
    match = re.search(r'(\d{8})', filename)
    if match:
        date_str = match.group(1)
        return datetime.strptime(date_str, "%Y%m%d")
    return None


def sync_daily_digest():
    """åŒæ­¥æ¯æ—¥ç®€æŠ¥åˆ° Hugo"""
    print("ğŸ”„ å¼€å§‹åŒæ­¥æ¯æ—¥ç®€æŠ¥...")

    daily_path = CONTENT_FORGE_AI_PATH / "data" / "daily"
    hugo_daily_path = HUGO_CONTENT_PATH / "daily"

    # åˆ›å»º Hugo daily ç›®å½•
    hugo_daily_path.mkdir(parents=True, exist_ok=True)

    # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
    for date_dir in sorted(daily_path.iterdir()):
        if not date_dir.is_dir() or date_dir.name.startswith('.'):
            continue

        digest_dir = date_dir / "digest"
        if not digest_dir.exists():
            continue

        # æŸ¥æ‰¾æœ€æ–°çš„ digest æ–‡ä»¶
        md_files = sorted(digest_dir.glob("digest_*.md"), reverse=True)
        if not md_files:
            continue

        latest_md = md_files[0]
        json_file = latest_md.with_suffix('.json')

        # è§£ææ—¥æœŸ
        pub_date = parse_date_from_digest_filename(latest_md.name)
        if not pub_date:
            print(f"âš ï¸  æ— æ³•è§£ææ—¥æœŸ: {latest_md.name}")
            continue

        # è¯»å– Markdown å†…å®¹
        with open(latest_md, 'r', encoding='utf-8') as f:
            md_content = f.read()

        # æå–æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
        lines = md_content.split('\n')
        title = lines[0].replace('#', '').strip()
        content = '\n'.join(lines[1:]).strip()

        # è¯»å– JSON å…ƒæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        tags = ["AIç®€æŠ¥"]
        categories = ["æ¯æ—¥çƒ­ç‚¹"]
        description = ""

        if json_file.exists():
            with open(json_file, 'r', encoding='utf-8') as f:
                digest_data = json.load(f)

            # æå–æ ¸å¿ƒæ´å¯Ÿä½œä¸ºæ ‡ç­¾
            if 'core_insights' in digest_data:
                tags.extend([f"æ´å¯Ÿ: {insight[:20]}" for insight in digest_data['core_insights'][:3]])

            # æå–åˆ†ç±»
            if 'categories' in digest_data:
                def _cat_to_str(cat):
                    if isinstance(cat, dict):
                        # ä¼˜å…ˆ nameï¼Œå…¶æ¬¡ idï¼Œæœ€åè½¬å­—ç¬¦ä¸²
                        return cat.get('name') or cat.get('id') or str(cat)
                    return str(cat)

                categories.extend([_cat_to_str(c) for c in digest_data['categories']])

        # ç”Ÿæˆ Hugo front matter
        front_matter = f"""---
title: "{title}"
date: {pub_date.strftime('%Y-%m-%d')}
draft: false
tags: {tags}
categories: {categories}
description: "AIæ¯æ—¥çƒ­ç‚¹ Â· {pub_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
---

"""

        # å†™å…¥ Hugo æ–‡ä»¶
        hugo_filename = hugo_daily_path / f"{pub_date.strftime('%Y-%m-%d')}-index.md"
        with open(hugo_filename, 'w', encoding='utf-8') as f:
            f.write(front_matter + content)

        print(f"âœ… å·²åŒæ­¥: {hugo_filename.name}")

    print("âœ¨ æ¯æ—¥ç®€æŠ¥åŒæ­¥å®Œæˆ!")


def sync_series_articles():
    """åŒæ­¥ç³»åˆ—æ–‡ç« åˆ° Hugo"""
    print("ğŸ”„ å¼€å§‹åŒæ­¥ç³»åˆ—æ–‡ç« ...")

    series_path = CONTENT_FORGE_AI_PATH / "data" / "series"
    hugo_series_path = HUGO_CONTENT_PATH / "series"

    # åˆ›å»º Hugo series ç›®å½•
    hugo_series_path.mkdir(parents=True, exist_ok=True)

    # éå†æ‰€æœ‰ç³»åˆ— (LLM_series, ML_series)
    for category_dir in sorted(series_path.iterdir()):
        if not category_dir.is_dir() or category_dir.name.startswith('.'):
            continue

        category_name = category_dir.name
        print(f"ğŸ“š å¤„ç†åˆ†ç±»: {category_name}")

        # éå†è¯¥åˆ†ç±»ä¸‹çš„æ‰€æœ‰ series (series_1_llm_foundation, ml_series_1_ml_foundation, etc.)
        for series_dir in sorted(category_dir.iterdir()):
            if not series_dir.is_dir():
                continue
            if not (series_dir.name.startswith('series_') or series_dir.name.startswith('ml_series_')):
                continue

            # è·å–ç³»åˆ—åç§°
            series_name = series_dir.name
            print(f"  ğŸ“– å¤„ç†ç³»åˆ—: {series_name}")

            # éå†è¯¥ç³»åˆ—çš„æ‰€æœ‰ episode
            for episode_dir in sorted(series_dir.iterdir()):
                if not episode_dir.is_dir() or not episode_dir.name.startswith('episode_'):
                    continue

                # æŸ¥æ‰¾æ–‡ç« å’Œå…ƒæ•°æ®
                md_files = list(episode_dir.glob("*_article.md"))
                metadata_file = episode_dir / "episode_metadata.json"

                if not md_files or not metadata_file.exists():
                    continue

                article_file = md_files[0]

                # è¯»å–å…ƒæ•°æ®
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)

                # è·³è¿‡æœªå®Œæˆçš„æ–‡ç« 
                if metadata.get('status') != 'completed':
                    continue

                # è¯»å–æ–‡ç« å†…å®¹
                with open(article_file, 'r', encoding='utf-8') as f:
                    article_content = f.read()

                # æå–æ ‡é¢˜
                lines = article_content.split('\n')
                title = lines[0].replace('#', '').strip() if lines[0].startswith('#') else metadata['title']
                content = '\n'.join(lines[1:]).strip() if lines[0].startswith('#') else article_content

                # è§£ææ—¥æœŸ
                pub_date = datetime.strptime(metadata['completed_at'], "%Y-%m-%d")

                # è·å– episode ç¼–å·
                episode_num = metadata['episode']
                episode_str = f"{episode_num:03d}"

                # ç”Ÿæˆ Hugo front matter
                front_matter = f"""---
title: "{metadata['title']}"
date: {pub_date.strftime('%Y-%m-%d')}
draft: false
tags: {metadata['keywords']}
categories: ["{series_name}", "{metadata.get('difficulty', 'ä¸­çº§')}"]
description: "{metadata.get('description', metadata['title'])}"
series: "{series_name}"
episode: {episode_num}
difficulty: "{metadata.get('difficulty', 'ä¸­çº§')}"
estimatedWords: {metadata.get('estimated_words', 0)}
---

"""

                # åˆ›å»ºç³»åˆ—å­ç›®å½•
                series_subdir = hugo_series_path / series_name
                series_subdir.mkdir(exist_ok=True)

                # å†™å…¥ Hugo æ–‡ä»¶
                hugo_filename = series_subdir / f"{episode_str}-{metadata['title'].replace(' ', '-').replace('/', '-')}.md"
                with open(hugo_filename, 'w', encoding='utf-8') as f:
                    f.write(front_matter + content)

                print(f"  âœ… å·²åŒæ­¥: Episode {episode_num} - {metadata['title']}")

    print("âœ¨ ç³»åˆ—æ–‡ç« åŒæ­¥å®Œæˆ!")


def create_about_page():
    """åˆ›å»ºå…³äºé¡µé¢"""
    about_content = """---
title: "å…³äº AI Insights"
date: 2024-01-01
draft: false
---

# AI Insights

æ¬¢è¿æ¥åˆ° **AI Insights** - ä¸€ä¸ªç”± AI é©±åŠ¨çš„å¤šå¹³å°å†…å®¹è‡ªåŠ¨åŒ–ç”Ÿäº§å·¥å‚ã€‚

## æˆ‘ä»¬æä¾›ä»€ä¹ˆ

### ğŸ“° æ¯æ—¥ AI ç®€æŠ¥

æ¯å¤©æ›´æ–°ï¼Œæ±‡é›†å…¨çƒ AI é¢†åŸŸæœ€æ–°åŠ¨æ€ï¼ŒåŒ…æ‹¬ï¼š
- äº§ä¸šåŠ¨æ€
- å­¦æœ¯å‰æ²¿
- æŠ€æœ¯åˆ›æ–°
- äº§å“å·¥å…·
- è¡Œä¸šåº”ç”¨

### ğŸ“š ç³»åˆ—æŠ€æœ¯æ–‡ç« 

ç³»ç»ŸåŒ–çš„ AI æŠ€æœ¯å­¦ä¹ èµ„æºï¼Œæ¶µç›–ï¼š
- **LLM ç³»åˆ—** - å¤§è¯­è¨€æ¨¡å‹åŸç†ä¸åº”ç”¨ï¼ˆ100æœŸï¼‰
- **ML ç³»åˆ—** - æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ï¼ˆ100æœŸï¼‰

## æŠ€æœ¯æ ˆ

æœ¬åšå®¢åŸºäºä»¥ä¸‹æŠ€æœ¯æ„å»ºï¼š

- **Hugo** - é™æ€ç½‘ç«™ç”Ÿæˆå™¨
- **Paper ä¸»é¢˜** - ç®€æ´ç°ä»£çš„åšå®¢ä¸»é¢˜
- **ContentForge AI** - å†…å®¹è‡ªåŠ¨åŒ–ç”Ÿäº§ç³»ç»Ÿ
- **GitHub Pages** - ç½‘ç«™æ‰˜ç®¡

## è”ç³»æˆ‘ä»¬

- GitHub: [Ming-H/content-forge-ai](https://github.com/Ming-H/content-forge-ai)
- å®˜ç½‘: [DevFox AI](https://www.devfoxai.cn/)

---

*ç”± ContentForge AI è‡ªåŠ¨ç”Ÿæˆä¸ç»´æŠ¤*
"""

    about_path = HUGO_CONTENT_PATH / "about.md"
    with open(about_path, 'w', encoding='utf-8') as f:
        f.write(about_content)

    print("âœ… å…³äºé¡µé¢å·²åˆ›å»º")


def create_index_page():
    """åˆ›å»ºé¦–é¡µ"""
    index_content = """---
title: "AI Insights"
---

æ¬¢è¿æ¥åˆ° **AI Insights**!

è¿™é‡Œæ±‡é›†äº†æœ€æ–°çš„ AI è¡Œä¸šåŠ¨æ€å’Œæ·±åº¦çš„æŠ€æœ¯æ–‡ç« ã€‚

## æœ€æ–°å†…å®¹

### ğŸ“° æ¯æ—¥ç®€æŠ¥

æ¯å¤©æ›´æ–°ï¼Œæ±‡é›†å…¨çƒ AI é¢†åŸŸæœ€æ–°åŠ¨æ€ã€‚

[æŸ¥çœ‹å…¨éƒ¨ç®€æŠ¥](/daily/)

### ğŸ“š ç³»åˆ—æ–‡ç« 

ç³»ç»ŸåŒ–çš„ AI æŠ€æœ¯å­¦ä¹ èµ„æºã€‚

- **[LLM ç³»åˆ—](/series/llm_series/)** - å¤§è¯­è¨€æ¨¡å‹åŸç†ä¸åº”ç”¨ï¼ˆ100æœŸï¼‰
- **[ML ç³»åˆ—](/series/ml_series/)** - æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ï¼ˆ100æœŸï¼‰

## å…³äº

æœ¬åšå®¢ç”± [ContentForge AI](https://github.com/Ming-H/content-forge-ai) è‡ªåŠ¨ç”Ÿæˆä¸ç»´æŠ¤ã€‚
"""

    index_path = HUGO_CONTENT_PATH / "_index.md"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_content)

    print("âœ… é¦–é¡µå·²åˆ›å»º")


def main():
    parser = argparse.ArgumentParser(description='åŒæ­¥ content-forge-ai å†…å®¹åˆ° Hugo åšå®¢')
    parser.add_argument('--daily', action='store_true', help='åŒæ­¥æ¯æ—¥ç®€æŠ¥')
    parser.add_argument('--series', action='store_true', help='åŒæ­¥ç³»åˆ—æ–‡ç« ')
    parser.add_argument('--all', action='store_true', help='åŒæ­¥å…¨éƒ¨å†…å®¹')
    parser.add_argument('--pages', action='store_true', help='åˆ›å»ºåŸºç¡€é¡µé¢')

    args = parser.parse_args()

    if args.pages or args.all:
        create_index_page()
        create_about_page()

    if args.daily or args.all:
        sync_daily_digest()

    if args.series or args.all:
        sync_series_articles()

    if not any([args.daily, args.series, args.all, args.pages]):
        parser.print_help()


if __name__ == "__main__":
    main()
